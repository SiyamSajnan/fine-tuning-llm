{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNFewUrtUaFg"
      },
      "outputs": [],
      "source": [
        "! pip install datasets ipywidgets transformers accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWJYPqj-JTYq"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e5OB8685hWHW"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional, Union, Any, Tuple\n",
        "from datasets import load_dataset, concatenate_datasets, Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments, AutoModelForCausalLM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "from scipy.stats import spearmanr\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYyZ-fo-UaFi",
        "outputId": "66f07a6c-fd33-42c6-d643-07b203a0a185"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKd63ogoJZYp"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzXAVVK4UaFi"
      },
      "source": [
        "The Tokenizer method, for now the maximum length is fixed to 512..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wlya304lhWHX"
      },
      "outputs": [],
      "source": [
        "class CustomDataTokenizer:\n",
        "    def __init__(self, tokenizer, is_classification=True, max_length = 512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.is_classification = is_classification\n",
        "\n",
        "    def __call__(self, data: Dict) -> Dict:\n",
        "        # For Classification Task: Only Text1 is required...\n",
        "        text_columns = ['text1']\n",
        "        if not self.is_classification:\n",
        "            text_columns.append('text2')\n",
        "\n",
        "        tokens_list = []\n",
        "        for text_column in text_columns:\n",
        "            # Tokenization happens here to get in the form which is accepted in the Objective Function...\n",
        "            tokens_list.append(self.tokenizer(data[text_column], max_length=self.max_length, truncation=True))\n",
        "\n",
        "        token = {}\n",
        "        seperate_ids = []\n",
        "        for i, t in enumerate(tokens_list):\n",
        "            for key, val in t.items():\n",
        "                if i == 0:\n",
        "                    token[key] = val\n",
        "                else:\n",
        "                    token[key] += val\n",
        "                if key == 'input_ids':\n",
        "                    seperate_ids += [i] * len(val)\n",
        "\n",
        "        token['labels'] = [int(data['label']) if 'label' in data else -1]\n",
        "        token['seperate_ids'] = seperate_ids\n",
        "\n",
        "        return token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf43nyBfJpUi"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkSrRaOJUaFj"
      },
      "source": [
        "The loss functions:\n",
        "\n",
        "y_true and y_pred must be zigzag style, such as [x[0][0], x[0][1], x[1][0], x[1][1], ...], where (x[0][0], x[0][1]) stands for a pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZOw5jWY2hWHX"
      },
      "outputs": [],
      "source": [
        "def categorical_crossentropy(y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor:\n",
        "    return -(F.log_softmax(y_pred, dim=1) * y_true).sum(dim=1)\n",
        "\n",
        "def cosine_loss(y_true: torch.Tensor, y_pred: torch.Tensor, tau: float=20.0) -> torch.Tensor:\n",
        "    y_true = y_true[::2, 0]\n",
        "    y_true = (y_true[:, None] < y_true[None, :]).float()\n",
        "    y_pred = F.normalize(y_pred, p=2, dim=1)\n",
        "    y_pred = torch.sum(y_pred[::2] * y_pred[1::2], dim=1) * tau\n",
        "    y_pred = y_pred[:, None] - y_pred[None, :]\n",
        "    y_pred = (y_pred - (1 - y_true) * 1e12).view(-1)\n",
        "    zero = torch.Tensor([0]).to(y_pred.device)\n",
        "    y_pred = torch.concat((zero, y_pred), dim=0)\n",
        "    return torch.logsumexp(y_pred, dim=0)\n",
        "\n",
        "def angle_loss(y_true: torch.Tensor, y_pred: torch.Tensor, tau: float=1.0):\n",
        "    y_true = y_true[::2, 0]\n",
        "    y_true = (y_true[:, None] < y_true[None, :]).float()\n",
        "\n",
        "    y_pred_re, y_pred_im = torch.chunk(y_pred, 2, dim=1)\n",
        "    a = y_pred_re[::2]\n",
        "    b = y_pred_im[::2]\n",
        "    c = y_pred_re[1::2]\n",
        "    d = y_pred_im[1::2]\n",
        "\n",
        "    z = torch.sum(c**2 + d**2, dim=1, keepdim=True)\n",
        "    re = (a * c + b * d) / z\n",
        "    im = (b * c - a * d) / z\n",
        "\n",
        "    dz = torch.sum(a**2 + b**2, dim=1, keepdim=True)**0.5\n",
        "    dw = torch.sum(c**2 + d**2, dim=1, keepdim=True)**0.5\n",
        "    re /= (dz / dw)\n",
        "    im /= (dz / dw)\n",
        "\n",
        "    y_pred = torch.concat((re, im), dim=1)\n",
        "    y_pred = torch.abs(torch.sum(y_pred, dim=1)) * tau\n",
        "    y_pred = y_pred[:, None] - y_pred[None, :]\n",
        "    y_pred = (y_pred - (1 - y_true) * 1e12).view(-1)\n",
        "    zero = torch.Tensor([0]).to(y_pred.device)\n",
        "    y_pred = torch.concat((zero, y_pred), dim=0)\n",
        "    return torch.logsumexp(y_pred, dim=0)\n",
        "\n",
        "def in_batch_negative_loss(y_true: torch.Tensor,\n",
        "                           y_pred: torch.Tensor,\n",
        "                           tau: float=20.0,\n",
        "                           negative_weights: float=0.0) -> torch.Tensor:\n",
        "    device = y_true.device\n",
        "\n",
        "    def make_target_matrix(y_true: torch.Tensor):\n",
        "        idxs = torch.arange(0, y_pred.shape[0]).int().to(device)\n",
        "        y_true = y_true.int()\n",
        "        idxs_1 = idxs[None, :]\n",
        "        idxs_2 = (idxs + 1 - idxs % 2 * 2)[:, None]\n",
        "\n",
        "        idxs_1 *= y_true.T\n",
        "        idxs_1 += (y_true.T == 0).int() * -2\n",
        "\n",
        "        idxs_2 *= y_true\n",
        "        idxs_2 += (y_true == 0).int() * -1\n",
        "\n",
        "        y_true = (idxs_1 == idxs_2).float()\n",
        "        return y_true\n",
        "\n",
        "    neg_mask = make_target_matrix(y_true == 0)\n",
        "\n",
        "    y_true = make_target_matrix(y_true)\n",
        "\n",
        "    y_pred = F.normalize(y_pred, dim=1, p=2)\n",
        "    similarities = y_pred @ y_pred.T\n",
        "    similarities = similarities - torch.eye(y_pred.shape[0]).to(device) * 1e12\n",
        "    similarities = similarities * tau\n",
        "\n",
        "    if negative_weights > 0:\n",
        "        similarities += neg_mask * negative_weights\n",
        "\n",
        "    return categorical_crossentropy(y_true, similarities).mean()\n",
        "\n",
        "def contrastive_pairwise_comb_loss(y_true: torch.Tensor, y_pred: torch.Tensor, tau: float=1.0, margin=1) -> torch.Tensor:\n",
        "    y_true_pairs = y_true[::2, 0]\n",
        "    y_true_pairs = (y_true_pairs[:, None] < y_true_pairs[None, :]).float()\n",
        "    y_pred = F.normalize(y_pred, p=2, dim=1)\n",
        "\n",
        "    cosine_sim = torch.sum(y_pred[::2] * y_pred[1::2], dim=1) * tau\n",
        "\n",
        "    # Contrastive Loss...\n",
        "    pos_pairs = y_true_pairs * torch.pow(1 - cosine_sim, 2)\n",
        "    neg_pairs = (1 - y_true_pairs) * torch.pow(torch.clamp(cosine_sim - margin, min=0.0), 2)\n",
        "    contrastive_loss = torch.mean(pos_pairs + neg_pairs)\n",
        "\n",
        "    # Pairwise Ranking Loss...\n",
        "    y_pred_diff = cosine_sim[:, None] - cosine_sim[None, :]\n",
        "    y_true_diff = y_true_pairs[:, None] - y_true_pairs[None, :]\n",
        "    mask = (y_true_diff > 0).float()\n",
        "    pairwise_ranking_loss = torch.mean(mask * F.relu(1 - y_pred_diff))\n",
        "\n",
        "    combined_loss_value = contrastive_loss + pairwise_ranking_loss\n",
        "\n",
        "    return combined_loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK2iP0OXmiLv"
      },
      "source": [
        "### Combined Loss Function of Contrastive Loss and Pairwise Ranking Loss\n",
        "\n",
        "The combined loss function aims to improve the performance of sentence embeddings by incorporating contrastive loss, pairwise ranking loss, and ensuring the embeddings are normalized. Here's a detailed explanation of each step in the loss function:\n",
        "\n",
        "#### 1. Input Preparation\n",
        "\n",
        "```python\n",
        "y_true_pairs = y_true[::2, 0]\n",
        "y_true_pairs = (y_true_pairs[:, None] < y_true_pairs[None, :]).float()\n",
        "```\n",
        "\n",
        "- **Purpose**: This step prepares the ground truth labels (`y_true`) for use in the loss calculations.\n",
        "- **Details**:\n",
        "  - The `y_true` tensor is expected to be in a zigzag style, where pairs are alternately positioned.\n",
        "  - The `::2` indexing selects every other element, assuming pairs are positioned adjacently.\n",
        "  - The `<` operator creates a matrix where each element indicates if the row's pair score is less than the column's pair score. This matrix helps in identifying the positive and negative pairs for ranking.\n",
        "\n",
        "#### 2. Embedding Normalization\n",
        "\n",
        "```python\n",
        "y_pred = F.normalize(y_pred, p=2, dim=1)\n",
        "```\n",
        "\n",
        "- **Purpose**: Normalize the embeddings to ensure stable and meaningful cosine similarity calculations.\n",
        "- **Details**:\n",
        "  - Normalization ensures that the embeddings lie on the unit sphere, making the cosine similarity a reliable measure of similarity.\n",
        "  - `p=2` specifies L2 normalization, and `dim=1` normalizes along the feature dimension.\n",
        "\n",
        "#### 3. Cosine Similarity Calculation\n",
        "\n",
        "```python\n",
        "cosine_sim = torch.sum(y_pred[::2] * y_pred[1::2], dim=1) * tau\n",
        "```\n",
        "\n",
        "- **Purpose**: Calculate the cosine similarity between paired embeddings.\n",
        "- **Details**:\n",
        "  - `y_pred[::2]` and `y_pred[1::2]` select alternating embeddings, assuming they are paired.\n",
        "  - The dot product of these pairs gives the cosine similarity, scaled by a factor of `tau` to control the sharpness of similarity scores.\n",
        "\n",
        "#### 4. Contrastive Loss\n",
        "\n",
        "```python\n",
        "pos_pairs = y_true_pairs * torch.pow(1 - cosine_sim, 2)\n",
        "neg_pairs = (1 - y_true_pairs) * torch.pow(torch.clamp(cosine_sim - margin, min=0.0), 2)\n",
        "contrastive_loss = torch.mean(pos_pairs + neg_pairs)\n",
        "```\n",
        "\n",
        "- **Purpose**: Ensure that similar pairs are close and dissimilar pairs are separated by at least the margin.\n",
        "- **Details**:\n",
        "  - `pos_pairs` calculates the penalty for similar pairs based on how close their cosine similarity is to 1.\n",
        "  - `neg_pairs` calculates the penalty for dissimilar pairs, ensuring their similarity is less than the margin.\n",
        "  - `torch.clamp` ensures the penalty is only applied when the similarity is within the margin.\n",
        "  - The mean of these penalties gives the overall contrastive loss.\n",
        "\n",
        "#### 5. Pairwise Ranking Loss\n",
        "\n",
        "```python\n",
        "y_pred_diff = cosine_sim[:, None] - cosine_sim[None, :]\n",
        "y_true_diff = y_true_pairs[:, None] - y_true_pairs[None, :]\n",
        "mask = (y_true_diff > 0).float()\n",
        "pairwise_ranking_loss = torch.mean(mask * F.relu(1 - y_pred_diff))\n",
        "```\n",
        "\n",
        "- **Purpose**: Directly optimize the rank order of pairs to improve the Spearman's rank correlation coefficient.\n",
        "- **Details**:\n",
        "  - `y_pred_diff` calculates the difference in similarity scores between all pairs.\n",
        "  - `y_true_diff` calculates the difference in true scores to identify positive differences.\n",
        "  - `mask` ensures that only positive differences (where the row's score is less than the column's score) are considered.\n",
        "  - `F.relu(1 - y_pred_diff)` penalizes cases where the rank order is incorrect, ensuring a margin of 1.\n",
        "  - The mean of these penalties gives the overall pairwise ranking loss.\n",
        "\n",
        "#### 6. Combined Loss\n",
        "\n",
        "```python\n",
        "combined_loss_value = contrastive_loss + pairwise_ranking_loss\n",
        "```\n",
        "\n",
        "- **Purpose**: Combine the contrastive and pairwise ranking losses to create a robust training signal.\n",
        "- **Details**:\n",
        "  - The final loss value is a sum of the contrastive loss and pairwise ranking loss, balancing between separating embeddings and ensuring correct rank order.\n",
        "\n",
        "### Comparison with SimCSE\n",
        "\n",
        "SimCSE (Simple Contrastive Learning of Sentence Embeddings) focuses on using contrastive loss to improve sentence embeddings. Here are some key differences and advantages of the enhanced combined loss function:\n",
        "\n",
        "1. **Pairwise Ranking Optimization**:\n",
        "   - **Problem in SimCSE**: SimCSE uses a contrastive loss that encourages similar pairs to be close and dissimilar pairs to be far apart. However, it doesn't directly optimize for the rank order of pairs, which is crucial for tasks like STS where rank correlation is important.\n",
        "   - **Solution in Enhanced Loss**: The pairwise ranking loss directly optimizes the rank order, improving the Spearman's rank correlation coefficient.\n",
        "\n",
        "2. **Temperature Scaling (Tau)**:\n",
        "   - **Problem in SimCSE**: The scaling of similarity scores might not be explicitly controlled, which can affect the sharpness and stability of similarity scores.\n",
        "   - **Solution in Enhanced Loss**: The use of tau as a scaling factor ensures that the similarity scores are appropriately sharpened, aiding in better differentiation.\n",
        "\n",
        "3. **Combined Loss Components**:\n",
        "   - **Problem in SimCSE**: Relying solely on contrastive loss might not capture all the nuances required for rank-based evaluation metrics.\n",
        "   - **Solution in Enhanced Loss**: Combining contrastive loss with pairwise ranking loss ensures both good separation of embeddings and correct rank order, providing a more robust learning signal.\n",
        "\n",
        "This enhanced loss function addresses the limitations of SimCSE by integrating additional components that directly optimize the evaluation metric of interest, leading to potentially better performance in tasks requiring high rank correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Xwuv6RUaFk"
      },
      "source": [
        "Combining the loss functions with weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "adhkDi1bhWHX"
      },
      "outputs": [],
      "source": [
        "class TotalLoss:\n",
        "    def __init__(self,\n",
        "                w1: float = 1.0,\n",
        "                w2: float = 1.0,\n",
        "                w3: float = 1.0,\n",
        "                w4: float = 1.0,\n",
        "                cosine_tau: float = 20.0,\n",
        "                ibn_tau: float = 20,\n",
        "                angle_tau: float = 1.0,\n",
        "                con_tau: float = 1.0):\n",
        "        self.w1 = w1\n",
        "        self.w2 = w2\n",
        "        self.w3 = w3\n",
        "        self.w4 = w4\n",
        "        self.cosine_tau = cosine_tau\n",
        "        self.ibn_tau = ibn_tau\n",
        "        self.angle_tau = angle_tau\n",
        "        self.con_tau = con_tau\n",
        "\n",
        "    def __call__(self, labels: torch.Tensor, outputs: torch.Tensor) -> torch.Tensor:\n",
        "        loss = 0.\n",
        "        if self.w1 > 0:\n",
        "            loss += self.w1 * cosine_loss(labels, outputs, self.cosine_tau)\n",
        "        if self.w2 > 0:\n",
        "            loss += self.w2 * in_batch_negative_loss(labels, outputs, self.ibn_tau)\n",
        "        if self.w3 > 0:\n",
        "            loss += self.w3 * angle_loss(labels, outputs, self.angle_tau)\n",
        "        if self.w4 > 0:\n",
        "            loss += self.w4 * contrastive_pairwise_comb_loss(labels, outputs, self.con_tau)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXi45wR2KFFv"
      },
      "source": [
        "## Pooler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz8a3YGkUaFk"
      },
      "source": [
        "The different Pooling methods, using CLS for now, and Padding Strategy 'Left' for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xyFWXUQXhWHY"
      },
      "outputs": [],
      "source": [
        "class Pooler:\n",
        "    def __init__(self,\n",
        "                model,\n",
        "                # ['cls', 'cls_avg', 'last', 'avg', 'max', 'all', 'specific token index']\n",
        "                pooling_strategy: Optional[Union[int, str]] = 'cls',\n",
        "                padding_strategy: Optional[str] = 'left'):\n",
        "        self.model = model\n",
        "        self.pooling_strategy = pooling_strategy\n",
        "        self.padding_strategy = padding_strategy\n",
        "\n",
        "    def __call__(self, inputs) -> Any:\n",
        "        if self.pooling_strategy == 'last':\n",
        "            batch_size = inputs['input_ids'].shape[0]\n",
        "            if self.padding_strategy == 'left':\n",
        "                sequence_lengths = -1\n",
        "            else:\n",
        "                sequence_lengths = inputs[\"attention_mask\"].sum(dim=1) - 1\n",
        "\n",
        "        outputs = self.model(**inputs).last_hidden_state\n",
        "        if self.pooling_strategy == 'cls':\n",
        "            outputs = outputs[:, 0]\n",
        "        elif self.pooling_strategy == 'cls_avg':\n",
        "            outputs = (outputs[:, 0] + torch.mean(outputs, dim=1)) / 2.0\n",
        "        elif self.pooling_strategy == 'last':\n",
        "            outputs = outputs[torch.arange(batch_size, device=outputs.device), sequence_lengths]\n",
        "        elif self.pooling_strategy == 'avg':\n",
        "            outputs = torch.sum(\n",
        "                outputs * inputs[\"attention_mask\"][:, :, None], dim=1) / torch.sum(inputs[\"attention_mask\"])\n",
        "        elif self.pooling_strategy == 'max':\n",
        "            outputs, _ = torch.max(outputs * inputs[\"attention_mask\"][:, :, None], dim=1)\n",
        "        elif self.pooling_strategy == 'all':\n",
        "            return outputs\n",
        "        elif isinstance(self.pooling_strategy, int) or self.pooling_strategy.isnumeric():\n",
        "            return outputs[:, int(self.pooling_strategy)]\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVDqc2HoKXpU"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA8qbPXoUaFl"
      },
      "source": [
        "The custom trainer method which extends the Trainer method of Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0RpRE7z8hWHY"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, pooler: Pooler, loss_kwargs: Optional[Dict] = None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.pooler = pooler\n",
        "        if loss_kwargs is None:\n",
        "            loss_kwargs = {}\n",
        "        self.loss_fct = TotalLoss(**loss_kwargs)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\", None)\n",
        "        outputs = self.pooler(inputs)\n",
        "        loss = self.loss_fct(labels, outputs)\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDR2QBJiKnBf"
      },
      "source": [
        "## Data Collator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx8iSK42UaFl"
      },
      "source": [
        "The custom data collator which works with the trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xar9ji1NhWHY"
      },
      "outputs": [],
      "source": [
        "class CustomDataCollator:\n",
        "    tokenizer = None\n",
        "    padding = 'longest'\n",
        "    max_length: Optional[int] = 512\n",
        "    return_tensors: str = \"pt\"\n",
        "\n",
        "    def __init__(self, tokenizer_base):\n",
        "        self.tokenizer = tokenizer_base\n",
        "\n",
        "    def __call__(self, features: List[Dict], return_tensors: str = \"pt\") -> Dict[str, torch.Tensor]:\n",
        "        if return_tensors is None:\n",
        "            return_tensors = self.return_tensors\n",
        "        has_token_type_ids = \"token_type_ids\" in features[0]\n",
        "\n",
        "        new_features = []\n",
        "        for feature in features:\n",
        "            seperate_ids = feature['seperate_ids']\n",
        "            input_ids = feature['input_ids']\n",
        "            attention_mask = feature['attention_mask']\n",
        "            assert len(seperate_ids) == len(input_ids) == len(attention_mask)\n",
        "\n",
        "            has_token_type_ids = False\n",
        "            if \"token_type_ids\" in feature:\n",
        "                has_token_type_ids = True\n",
        "                token_type_ids = feature['token_type_ids']\n",
        "                assert len(token_type_ids) == len(input_ids)\n",
        "\n",
        "            max_seperate_id = max(seperate_ids)\n",
        "            prev_start_idx = 0\n",
        "            for seperate_id in range(1, max_seperate_id + 1):\n",
        "                start_idx = seperate_ids.index(seperate_id)\n",
        "\n",
        "                new_feature = {}\n",
        "                new_feature['input_ids'] = input_ids[prev_start_idx:start_idx]\n",
        "                new_feature['attention_mask'] = attention_mask[prev_start_idx:start_idx]\n",
        "                if has_token_type_ids:\n",
        "                    new_feature['token_type_ids'] = token_type_ids[prev_start_idx:start_idx]\n",
        "                new_feature['labels'] = feature['labels']\n",
        "                new_features.append(new_feature)\n",
        "                prev_start_idx = start_idx\n",
        "\n",
        "            new_feature = {}\n",
        "            new_feature['input_ids'] = input_ids[prev_start_idx:]\n",
        "            new_feature['attention_mask'] = attention_mask[prev_start_idx:]\n",
        "            if has_token_type_ids:\n",
        "                new_feature['token_type_ids'] = token_type_ids[prev_start_idx:]\n",
        "            new_feature['labels'] = feature['labels']\n",
        "            new_features.append(new_feature)\n",
        "\n",
        "        del features\n",
        "        features = self.tokenizer.pad(\n",
        "            {'input_ids': [feature['input_ids'] for feature in new_features]},\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=return_tensors,\n",
        "        )\n",
        "        features['attention_mask'] = self.tokenizer.pad(\n",
        "            {'input_ids': [feature['attention_mask'] for feature in new_features]},\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=return_tensors,\n",
        "        )['input_ids']\n",
        "        if has_token_type_ids:\n",
        "            features['token_type_ids'] = self.tokenizer.pad(\n",
        "                {'input_ids': [feature['token_type_ids'] for feature in new_features]},\n",
        "                padding=self.padding,\n",
        "                max_length=self.max_length,\n",
        "                return_tensors=return_tensors,\n",
        "            )['input_ids']\n",
        "        features['labels'] = torch.Tensor([feature['labels'] for feature in new_features])\n",
        "\n",
        "        return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDsjQhxkKq1Y"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajV4GQVDUaFm"
      },
      "source": [
        "The fit method which starts the training process, for now a lot of arguments have provided with default value..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_41sJ58WhWHY"
      },
      "outputs": [],
      "source": [
        "def fit(train_ds,\n",
        "        model_base,\n",
        "        tokenizer_base,\n",
        "        batch_size: int = 32,\n",
        "        output_dir: Optional[str] = 'chk/new_c',\n",
        "        epochs: int = 3,\n",
        "        learning_rate: float = 1e-5,\n",
        "        warmup_steps: int = 1000,\n",
        "        logging_steps: int = 10,\n",
        "        eval_steps: Optional[int] = None,\n",
        "        save_steps: int = 100,\n",
        "        save_strategy: str = 'steps',\n",
        "        save_total_limit: int = 10,\n",
        "        gradient_accumulation_steps: int = 1,\n",
        "        fp16: Optional[bool] = None,\n",
        "        argument_kwargs: Optional[Dict] = None,\n",
        "        trainer_kwargs: Optional[Dict] = None,\n",
        "        loss_kwargs: Optional[Dict] = None):\n",
        "\n",
        "    if argument_kwargs is None:\n",
        "        argument_kwargs = {}\n",
        "    if trainer_kwargs is None:\n",
        "        trainer_kwargs = {}\n",
        "    callbacks = None\n",
        "\n",
        "    pooler = Pooler(model_base)\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        pooler=pooler,\n",
        "        model=model_base,\n",
        "        train_dataset=train_ds,\n",
        "        loss_kwargs=loss_kwargs,\n",
        "        tokenizer=tokenizer_base,\n",
        "        args=TrainingArguments(\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "            warmup_steps=warmup_steps,\n",
        "            num_train_epochs=epochs,\n",
        "            learning_rate=learning_rate,\n",
        "            fp16=fp16,\n",
        "            logging_steps=logging_steps,\n",
        "            save_strategy=save_strategy,\n",
        "            eval_steps=eval_steps,\n",
        "            save_steps=save_steps,\n",
        "            output_dir=output_dir,\n",
        "            save_total_limit=save_total_limit,\n",
        "            load_best_model_at_end=False,\n",
        "            ddp_find_unused_parameters=None,\n",
        "            label_names=['labels', 'seperate_ids', 'extra'],\n",
        "            **argument_kwargs,\n",
        "        ),\n",
        "        callbacks=callbacks,\n",
        "        data_collator=CustomDataCollator(\n",
        "            tokenizer_base\n",
        "        ),\n",
        "        **trainer_kwargs\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    return model_base, tokenizer_base, pooler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpiS9-RxKuun"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CovZGEUAUaFm"
      },
      "source": [
        "The encode method to generate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SASA4fFghWHZ"
      },
      "outputs": [],
      "source": [
        "def encode(inputs: Union[List[str], Tuple[str], List[Dict], str],\n",
        "            model,\n",
        "            pooler,\n",
        "            tokenizer,\n",
        "            max_length: Optional[int] = 512,\n",
        "            to_numpy: bool = True,\n",
        "            device: Optional[Any] = 'cuda:0'):\n",
        "        if device is None:\n",
        "            device = 'cpu'\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        tokens = tokenizer(\n",
        "            inputs,\n",
        "            padding='longest',\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            return_tensors='pt')\n",
        "        tokens.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = pooler(tokens)\n",
        "        if to_numpy:\n",
        "            return output.float().detach().cpu().numpy()\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npUyhInUK6qZ"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_yqmnGuKxOH"
      },
      "source": [
        "## Data Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfBmu_0-6wGZ"
      },
      "source": [
        "SentEval Datasets Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b0x3s3P_6zAe"
      },
      "outputs": [],
      "source": [
        "def get_senteval_binary_data(dataset):\n",
        "    match dataset:\n",
        "        case 'CR':\n",
        "            pos_file = open(\"../Data/custrev.pos\", \"r\")\n",
        "            neg_file = open(\"../Data/custrev.neg\", \"r\")\n",
        "        case 'MPQA':\n",
        "            pos_file = open(\"../Data/mpqa.pos\", \"r\")\n",
        "            neg_file = open(\"../Data/mpqa.neg\", \"r\")\n",
        "        case 'MR':\n",
        "            pos_file = open(\"../Data/rt-polarity.pos\", \"r\")\n",
        "            neg_file = open(\"../Data/rt-polarity.neg\", \"r\")\n",
        "        case 'SUBJ':\n",
        "            pos_file = open(\"../Data/subj.objective\", \"r\")\n",
        "            neg_file = open(\"../Data/subj.subjective\", \"r\")\n",
        "\n",
        "    df_pos = pd.DataFrame()\n",
        "    pos_content = pos_file.readlines()\n",
        "    pos_file.close()\n",
        "    df_pos['sentence'] = pos_content\n",
        "    labels = np.ones(len(pos_content))\n",
        "    df_pos['label'] = labels.astype('int')\n",
        "\n",
        "    df_neg = pd.DataFrame()\n",
        "    neg_content = neg_file.readlines()\n",
        "    neg_file.close()\n",
        "    df_neg['sentence'] = neg_content\n",
        "    labels = np.zeros(len(neg_content))\n",
        "    df_neg['label'] = labels.astype('int')\n",
        "\n",
        "    df = pd.concat([df_pos, df_neg], axis=0, ignore_index=True)\n",
        "    df['sentence'] = df['sentence'].str.replace('\\n', '')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kG8RjUks61wY"
      },
      "outputs": [],
      "source": [
        "# SST -> We use the Binary classification...\n",
        "def get_sst_data():\n",
        "    train_file = open(\"../Data/sentiment-train\", \"r\")\n",
        "    train = train_file.readlines()\n",
        "    train_file.close()\n",
        "\n",
        "    sentence_train = []\n",
        "    label_train = []\n",
        "    for sentence in train:\n",
        "        sentence = sentence.strip()\n",
        "        label = int(sentence[len(sentence) - 1])\n",
        "        sentence = sentence[:-1].strip()\n",
        "        sentence_train.append(sentence)\n",
        "        label_train.append(label)\n",
        "\n",
        "    df_train = pd.DataFrame({'sentence': sentence_train, 'label': label_train})\n",
        "\n",
        "    test_file = open(\"../Data/sentiment-test\", \"r\")\n",
        "    test = test_file.readlines()\n",
        "    test_file.close()\n",
        "\n",
        "    sentence_test = []\n",
        "    label_test = []\n",
        "    for sentence in test:\n",
        "        sentence = sentence.strip()\n",
        "        label = int(sentence[len(sentence) - 1])\n",
        "        sentence = sentence[:-1].strip()\n",
        "        sentence_test.append(sentence)\n",
        "        label_test.append(label)\n",
        "\n",
        "    df_test = pd.DataFrame({'sentence': sentence_test, 'label': label_test})\n",
        "    df = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8Y3rYibz620e"
      },
      "outputs": [],
      "source": [
        "def get_senteval_dataset(name):\n",
        "    match name:\n",
        "        case 'CR':\n",
        "            return get_senteval_binary_data('CR')\n",
        "        case 'MPQA':\n",
        "            return get_senteval_binary_data('MPQA')\n",
        "        case 'MR':\n",
        "            return get_senteval_binary_data('MR')\n",
        "        case 'SST':\n",
        "            return get_sst_data()\n",
        "        case 'SUBJ':\n",
        "            return get_senteval_binary_data('SUBJ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ysILLEOe7CJr"
      },
      "outputs": [],
      "source": [
        "senteval_datasets = ['CR']#['CR', 'MPQA', 'MR', 'SUBJ']#, 'SST']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi9izGqz7rC7"
      },
      "source": [
        "STS Datasets Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SNHC4DNl7v7T"
      },
      "outputs": [],
      "source": [
        "def get_sts_dataset(dataset_name):\n",
        "    match dataset_name:\n",
        "        case 'STS-B':\n",
        "            dataset = load_dataset('mteb/stsbenchmark-sts', split='test')\n",
        "        case 'STS12':\n",
        "            dataset = load_dataset('mteb/sts12-sts', split='test')\n",
        "        case 'STS13':\n",
        "            dataset = load_dataset('mteb/sts13-sts', split='test')\n",
        "        case 'STS14':\n",
        "            dataset = load_dataset('mteb/sts14-sts', split='test')\n",
        "        case 'STS15':\n",
        "            dataset = load_dataset('mteb/sts15-sts', split='test')\n",
        "        case 'STS16':\n",
        "            dataset = load_dataset('mteb/sts16-sts', split='test')\n",
        "        case 'SICK-R':\n",
        "            dataset = load_dataset('mteb/sickr-sts', split='test')\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "zMWL7F6P8EG6"
      },
      "outputs": [],
      "source": [
        "sts_datasets = ['STS12']#['STS-B', 'STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'SICK-R']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlAwf-fRaFIL"
      },
      "source": [
        "## Objective Function Combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGj_X7A8LAwZ"
      },
      "source": [
        "Using the 3 provided objective functions and their 7 possible combinations for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "s9vafqNKa_-t"
      },
      "outputs": [],
      "source": [
        "def get_objective_function_weights(combi):\n",
        "    match combi:\n",
        "        case 'Cosine': return (1, 0, 0, 0)\n",
        "        case 'In-Batch Negatives': return (0, 1, 0, 0)\n",
        "        case 'Angle': return (0, 0, 1, 0)\n",
        "        case 'Contrastive-Pairwise': return (0, 0, 0, 1)\n",
        "        case 'Cosine + In-Batch Negatives': return (1, 1, 0, 0)\n",
        "        case 'Cosine + Angle': return (1, 0, 1, 0)\n",
        "        case 'Cosine + Contrastive-Pairwise': return (1, 0, 0, 1)\n",
        "        case 'In-Batch Negatives + Angle': return (0, 1, 1, 0)\n",
        "        case 'In-Batch Negatives + Contrastive-Pairwise': return (0, 1, 0, 1)\n",
        "        case 'Angle + Contrastive-Pairwise': return (0, 0, 1, 1)\n",
        "        case 'Cosine + In-Batch Negatives + Angle': return (1, 1, 1, 0)\n",
        "        case 'Cosine + In-Batch Negatives + Contrastive-Pairwise': return (1, 1, 0, 1)\n",
        "        case 'Cosine + Angle + Contrastive-Pairwise': return (1, 0, 1, 1)\n",
        "        case 'In-Batch Negatives + Angle + Contrastive-Pairwise': return (0, 1, 1, 1)\n",
        "        case 'Cosine + In-Batch Negatives + Angle + Contrastive-Pairwise': return (1, 1, 1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "hAEJCLCEaQ0Q"
      },
      "outputs": [],
      "source": [
        "objective_functions = [\n",
        "    # 'Cosine',\n",
        "    # 'In-Batch Negatives',\n",
        "    # 'Angle',\n",
        "    # 'Contrastive-Pairwise',\n",
        "    # 'Cosine + In-Batch Negatives',\n",
        "    # 'Cosine + Angle',\n",
        "    # 'Cosine + Contrastive-Pairwise',\n",
        "    # 'In-Batch Negatives + Angle',\n",
        "    # 'In-Batch Negatives + Contrastive-Pairwise',\n",
        "    # 'Angle + Contrastive-Pairwise',\n",
        "    # 'Cosine + In-Batch Negatives + Angle',\n",
        "    # 'Cosine + In-Batch Negatives + Contrastive-Pairwise',\n",
        "    # 'Cosine + Angle + Contrastive-Pairwise',\n",
        "    # 'In-Batch Negatives + Angle + Contrastive-Pairwise',\n",
        "    'Cosine + In-Batch Negatives + Angle + Contrastive-Pairwise'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xszL7wkILGFh"
      },
      "source": [
        "## Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGBEfvPVhWHZ"
      },
      "source": [
        "Base Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "UeMjLiE--JRS"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    # 'bert-base-uncased',\n",
        "    # 'bert-base-cased',\n",
        "    # 'bert-large-uncased',\n",
        "    # 'bert-large-cased',\n",
        "    # 'FacebookAI/roberta-base',\n",
        "    # 'sentence-transformers/all-mpnet-base-v2',\n",
        "    'princeton-nlp/sup-simcse-roberta-large',\n",
        "    # 'xuanye/cosent-similarity-text2vec',\n",
        "    # 'kornwtp/sup-consert-large'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KciCira7LJpg"
      },
      "source": [
        "## Driver Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8VR7dhZLh55"
      },
      "source": [
        "### SentEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "FtecQezwb5Ui"
      },
      "outputs": [],
      "source": [
        "def driver_senteval():\n",
        "    results_matrix = []\n",
        "\n",
        "    for model in models:\n",
        "        results_obj_matrix = []\n",
        "        for objective in objective_functions:\n",
        "            # Objective Functions Preparation...\n",
        "            w1_combi, w2_combi, w3_combi, w4_combi = get_objective_function_weights(objective)\n",
        "            results_obj_ds_matrix = []\n",
        "\n",
        "            for dataset in senteval_datasets:\n",
        "                # Model Preparation...\n",
        "                tokenizer_base = AutoTokenizer.from_pretrained(model)\n",
        "                model_base = AutoModel.from_pretrained(model)\n",
        "\n",
        "                # Dataset Preparation...\n",
        "                df = get_senteval_dataset(dataset)\n",
        "                ds = Dataset.from_pandas(df)\n",
        "                ds = ds.rename_column('sentence', 'text1')\n",
        "                if dataset == 'MR':\n",
        "                    ds = concatenate_datasets([ds.select(range(0, 231)), ds.select(range(233, 7463))])\n",
        "\n",
        "                split_ds = ds.train_test_split(test_size=0.3, seed=42)\n",
        "                ds_train = split_ds['train']\n",
        "                ds_test = split_ds['test']\n",
        "\n",
        "                # Tokenization...\n",
        "                train_ds = ds_train.shuffle().map(CustomDataTokenizer(tokenizer_base), num_proc=8)\n",
        "\n",
        "                # Model Training...\n",
        "                model_new, tokenizer_new, pooler_new = fit(\n",
        "                    train_ds=train_ds,\n",
        "                    model_base=model_base,\n",
        "                    tokenizer_base=tokenizer_base,\n",
        "                    output_dir='chk/c',\n",
        "                    batch_size=32,\n",
        "                    epochs=5,\n",
        "                    learning_rate=2e-5,\n",
        "                    save_steps=0,\n",
        "                    eval_steps=100,\n",
        "                    warmup_steps=0,\n",
        "                    gradient_accumulation_steps=1,\n",
        "                    loss_kwargs={\n",
        "                        'w1': w1_combi,\n",
        "                        'w2': w2_combi,\n",
        "                        'w3': w3_combi,\n",
        "                        'w4': w4_combi,\n",
        "                        'cosine_tau': 20,\n",
        "                        'ibn_tau': 20,\n",
        "                        'angle_tau': 1.0,\n",
        "                        'con_tau': 1.2\n",
        "                    },\n",
        "                    fp16=True,\n",
        "                    logging_steps=1000\n",
        "                )\n",
        "\n",
        "                # Embedding Generation for Train and Test sets... Doing line-by-line embeddings for now...\n",
        "                emb_train = []\n",
        "                for sentence in ds_train['text1']:\n",
        "                    emb_train.append(encode(sentence, model_new, pooler_new, tokenizer_new)[0])\n",
        "\n",
        "                emb_test = []\n",
        "                for sentence in ds_test['text1']:\n",
        "                    emb_test.append(encode(sentence, model_new, pooler_new, tokenizer_new)[0])\n",
        "\n",
        "                # Conversion into Numpy Array...\n",
        "                emb_train = np.array(emb_train)\n",
        "                emb_test = np.array(emb_test)\n",
        "\n",
        "                # Classification...\n",
        "                lr = LogisticRegression(max_iter=10000)\n",
        "                lr.fit(emb_train, ds_train['label'])\n",
        "                accuracy_score = lr.score(emb_test, ds_test['label'])\n",
        "                \n",
        "                base_dir = '../Files/STS_Results/'\n",
        "                file_name = 'STS_' + dataset + '_' + model[0].replace('/', '-') + '.npy'\n",
        "                with open(base_dir + file_name, 'wb') as f:\n",
        "                    np.save(f, accuracy_score)\n",
        "                \n",
        "                results_obj_ds_matrix.append(accuracy_score)\n",
        "            results_obj_matrix.append(results_obj_ds_matrix)\n",
        "        results_matrix.append(results_obj_matrix)\n",
        "    return results_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoik9A2OLk5R"
      },
      "source": [
        "### STS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kj-Y2cnGhWHc"
      },
      "outputs": [],
      "source": [
        "def calculate_cosine_similarity(sentence1_vec, sentence2_vec):\n",
        "    cosine_similarity = np.dot(sentence1_vec, sentence2_vec) / (np.linalg.norm(sentence1_vec) * np.linalg.norm(sentence2_vec))\n",
        "    return cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XWhPIBI7AAWo"
      },
      "outputs": [],
      "source": [
        "def calculate_Spearman_rank_correlation_coefficient(scores, scores_actual):\n",
        "    sc, _ = spearmanr(scores, scores_actual)\n",
        "    return sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "4dMgwpWqAAWo"
      },
      "outputs": [],
      "source": [
        "def driver_sts():\n",
        "    results_matrix = []\n",
        "\n",
        "    for model in models:\n",
        "        results_obj_matrix = []\n",
        "        for objective in objective_functions:\n",
        "            # Objective Functions Preparation...\n",
        "            w1_combi, w2_combi, w3_combi, w4_combi = get_objective_function_weights(objective)\n",
        "            results_obj_ds_matrix = []\n",
        "\n",
        "            for dataset in sts_datasets:\n",
        "                # Model Preparation...\n",
        "                tokenizer_base = AutoTokenizer.from_pretrained(model)\n",
        "                model_base = AutoModel.from_pretrained(model)\n",
        "\n",
        "                # Dataset Preparation...\n",
        "                ds = get_sts_dataset(dataset)\n",
        "                ds = ds.rename_column('sentence1', 'text1')\n",
        "                ds = ds.rename_column('sentence2', 'text2')\n",
        "                ds = ds.rename_column('score', 'label')\n",
        "\n",
        "                split_ds = ds.train_test_split(test_size=0.3, seed=42)\n",
        "                ds_train = split_ds['train']\n",
        "                ds_test = split_ds['test']\n",
        "\n",
        "                # Tokenization of train dataset...\n",
        "                train_ds = ds_train.shuffle().map(CustomDataTokenizer(tokenizer_base, is_classification=False), num_proc=8)\n",
        "\n",
        "                # Model Training...\n",
        "                model_new, tokenizer_new, pooler_new = fit(\n",
        "                    train_ds=train_ds,\n",
        "                    model_base=model_base,\n",
        "                    tokenizer_base=tokenizer_base,\n",
        "                    output_dir='chk/c',\n",
        "                    batch_size=32,\n",
        "                    epochs=5,\n",
        "                    learning_rate=2e-5,\n",
        "                    save_steps=0,\n",
        "                    eval_steps=100,\n",
        "                    warmup_steps=0,\n",
        "                    gradient_accumulation_steps=1,\n",
        "                    loss_kwargs={\n",
        "                        'w1': w1_combi,\n",
        "                        'w2': w2_combi,\n",
        "                        'w3': w3_combi,\n",
        "                        'w4': w4_combi,\n",
        "                        'cosine_tau': 20,\n",
        "                        'ibn_tau': 20,\n",
        "                        'angle_tau': 1.0,\n",
        "                        'con_tau': 1.2\n",
        "                    },\n",
        "                    fp16=True,\n",
        "                    logging_steps=1000\n",
        "                )\n",
        "\n",
        "                # Generating embeddings of STS dataset using the newly trained model...\n",
        "                emb_sentence_1 = encode(ds_test['text1'], model_new, pooler_new, tokenizer_new) # generating embeddings for test set sentence 1\n",
        "                emb_sentence_2 = encode(ds_test['text2'], model_new, pooler_new, tokenizer_new) # generating embeddings for test set sentence 2\n",
        "\n",
        "                # Calculating Spearman for AnglE...\n",
        "                cos_score = []\n",
        "                for i in range(emb_sentence_1.shape[0]):\n",
        "                    cos_score.append(calculate_cosine_similarity(emb_sentence_1[i], emb_sentence_2[i]))\n",
        "\n",
        "                spearman = calculate_Spearman_rank_correlation_coefficient(cos_score, ds_test['label'])\n",
        "                \n",
        "                base_dir = '../Files/STS_Results/'\n",
        "                file_name = 'STS_' + dataset + '_' + model[0].replace('/', '-') + '.npy'\n",
        "                with open(base_dir + file_name, 'wb') as f:\n",
        "                    np.save(f, spearman)\n",
        "                \n",
        "                results_obj_ds_matrix.append(spearman)\n",
        "            results_obj_matrix.append(results_obj_ds_matrix)\n",
        "        results_matrix.append(results_obj_matrix)\n",
        "    return results_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOkPXS5_LXM5"
      },
      "source": [
        "### Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "LGWYzer1AAWo",
        "outputId": "88bad540-4cd1-44bc-f5ac-6cf2f9efbe78"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f88b3199720d47099d466e4fbb8d55eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/2175 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [340/340 01:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results_matrix_sts = driver_sts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1H3yHmCa3U1",
        "outputId": "4d0f8ab7-cfe1-44ca-dd38-95172bd89f88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[[0.8604430074444147]]]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_matrix_sts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "723a89a69f5e4ad58bddb313a9dcf082",
            "d84521851c7d48b69ba88461bd337458",
            "10d6d3d1a3ce4af4a4c5bbd28b5c317b",
            "f8e64c7d5e8547afbb986c0ca4bb6f14",
            "fc1a3dcd0ed94737a4de4d8468a2afe5",
            "b9d12622318a45be85a218115a62bb46",
            "4643a49f0b30415db80c1151cd29a7ce",
            "b89294729fbe4faa8e5788b6708a1ef5",
            "1796c7cf621f4961b6bcb5c1c6a24402",
            "2dd9ae066c1d4e2684784dbb95905c62",
            "1f651f94396842a083f96319f8f1064b"
          ]
        },
        "id": "M2T82nNvfW6T",
        "outputId": "3abe9da6-078e-47c9-f66b-84a2ef748226"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a08dc02e11f8450a8ac7447cce7f0e89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/2642 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='415' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [415/415 02:01, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results_matrix_senteval = driver_senteval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBAIQE2punSe",
        "outputId": "712481d9-3a76-402d-d718-8f3a2609dcf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[[0.9143865842894969]]]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_matrix_senteval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m5rbe2hLZeo"
      },
      "source": [
        "### Saving the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdDsIykFAAWt"
      },
      "outputs": [],
      "source": [
        "with open('../Results/BERT_SentEval_Results_New_Loss.npy', 'wb') as f:\n",
        "    np.save(f, results_matrix_senteval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAJd7esKAAWu"
      },
      "outputs": [],
      "source": [
        "with open('../Results/BERT_STS_Results_New_Loss.npy', 'wb') as f:\n",
        "    np.save(f, results_matrix_sts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W8o9ZmMUaFn"
      },
      "source": [
        "# NLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYV5wydqUaFn"
      },
      "outputs": [],
      "source": [
        "def load_all_nli(exclude_neutral=True):\n",
        "    label_mapping = {\n",
        "        'entailment': 1,  # '0' (entailment)\n",
        "        'neutral': 1,\n",
        "        'contradiction': 0   # '2' (contradiction)\n",
        "    }\n",
        "    data = []\n",
        "    with gzip.open('AllNLI.tsv.gz', 'rt', encoding='utf8') as fIn:\n",
        "        reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
        "        for row in reader:\n",
        "            if row['split'] == 'train' and row['label'] != 'neutral':\n",
        "                if exclude_neutral and row['label'] == 'neutral':\n",
        "                    continue\n",
        "                sent1 = row['sentence1'].strip()\n",
        "                sent2 = row['sentence2'].strip()\n",
        "                data.append({'text1': sent1, 'text2': sent2, 'label': label_mapping[row['label']]})\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwC1copcUaFn"
      },
      "outputs": [],
      "source": [
        "def preprocess_nli():\n",
        "    train_data = load_all_nli()\n",
        "    nli_dataset = {}\n",
        "    train_ds = Dataset.from_list(train_data)\n",
        "    nli_dataset['train'] = train_ds\n",
        "    nli_dataset = DatasetDict(nli_dataset)\n",
        "    ds_train = nli_dataset['train']\n",
        "    return ds_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-k7PuBPhWHb"
      },
      "source": [
        "Training with AnglE losses..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q85vBUkUaFn"
      },
      "outputs": [],
      "source": [
        "def train_nli(ds_train, model_base, tokenizer_base):\n",
        "    train_ds = ds_train.shuffle().map(CustomDataTokenizer(tokenizer_base), num_proc=8)\n",
        "    model_new, tokenizer_new, pooler_new = fit(\n",
        "        train_ds=train_ds,\n",
        "        model_base=model_base,\n",
        "        tokenizer_base=tokenizer_base,\n",
        "        output_dir='chk/c',\n",
        "        batch_size=32,\n",
        "        epochs=5,\n",
        "        learning_rate=2e-5,\n",
        "        save_steps=0,\n",
        "        eval_steps=100,\n",
        "        warmup_steps=0,\n",
        "        gradient_accumulation_steps=1,\n",
        "        loss_kwargs={\n",
        "            'w1': 1.0,\n",
        "            'w2': 1.0,\n",
        "            'w3': 1.0\n",
        "            'cosine_tau': 20,\n",
        "            'ibn_tau': 20,\n",
        "            'angle_tau': 1.0\n",
        "        },\n",
        "        fp16=True,\n",
        "        logging_steps=1000\n",
        "    )\n",
        "    return model_new, tokenizer_new, pooler_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IntQVlnn4h65"
      },
      "source": [
        "### Mathematical Comparison: Enhanced Combined Loss vs. SimCSE\n",
        "\n",
        "#### SimCSE Loss Function\n",
        "\n",
        "SimCSE uses a contrastive loss to learn sentence embeddings. The mathematical formulation of the contrastive loss in SimCSE is as follows:\n",
        "\n",
        "**Contrastive Loss (SimCSE)**:\n",
        "\\[\n",
        "\\mathcal{L}_{\\text{SimCSE}} = - \\log \\frac{\\exp(\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+))}{\\sum_{j=1}^{N} \\exp(\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_j))}\n",
        "\\]\n",
        "\n",
        "- \\(\\mathbf{h}_i\\): Embedding of the anchor sentence.\n",
        "- \\(\\mathbf{h}_i^+\\): Embedding of the positive pair (similar sentence).\n",
        "- \\(\\mathbf{h}_j\\): Embeddings of all sentences in the batch (including negatives).\n",
        "- \\(\\text{sim}(\\mathbf{u}, \\mathbf{v})\\): Cosine similarity between embeddings \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\).\n",
        "\n",
        "This loss encourages the cosine similarity between the anchor and positive pair to be high while pushing the similarities between the anchor and all other (negative) samples to be low.\n",
        "\n",
        "#### Enhanced Combined Loss Function\n",
        "\n",
        "The enhanced combined loss function incorporates contrastive loss, pairwise ranking loss, and normalization. Here’s the detailed mathematical formulation:\n",
        "\n",
        "**1. Contrastive Loss**:\n",
        "\n",
        "\\[\n",
        "\\mathcal{L}_{\\text{contrastive}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot (1 - \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+))^2 + (1 - y_i) \\cdot \\max(0, \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{margin})^2 \\right]\n",
        "\\]\n",
        "\n",
        "- \\(y_i\\): Binary label indicating whether \\(\\mathbf{h}_i\\) and \\(\\mathbf{h}_i^+\\) are similar (1) or dissimilar (0).\n",
        "- \\(\\text{margin}\\): Margin parameter ensuring dissimilar pairs have at least this distance in similarity.\n",
        "\n",
        "**2. Pairwise Ranking Loss**:\n",
        "\n",
        "\\[\n",
        "\\mathcal{L}_{\\text{ranking}} = \\frac{1}{N} \\sum_{i,j} \\left[ \\max(0, 1 - (\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{sim}(\\mathbf{h}_j, \\mathbf{h}_j^-))) \\cdot \\mathbb{I}(y_i > y_j) \\right]\n",
        "\\]\n",
        "\n",
        "- \\(\\mathbb{I}(y_i > y_j)\\): Indicator function that is 1 if \\(y_i > y_j\\) (indicating the rank order is correct), and 0 otherwise.\n",
        "- \\(\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+)\\): Similarity score for positive pair.\n",
        "- \\(\\text{sim}(\\mathbf{h}_j, \\mathbf{h}_j^-)\\): Similarity score for negative pair.\n",
        "\n",
        "**3. Combined Loss**:\n",
        "\n",
        "The final combined loss function integrates the contrastive and pairwise ranking losses:\n",
        "\n",
        "\\[\n",
        "\\mathcal{L}_{\\text{combined}} = \\mathcal{L}_{\\text{contrastive}} + \\mathcal{L}_{\\text{ranking}}\n",
        "\\]\n",
        "\n",
        "**4. Normalization and Scaling with Tau**:\n",
        "\n",
        "Normalization ensures embeddings are on the unit sphere, making cosine similarity a reliable measure. The scaling factor \\(\\tau\\) controls the sharpness of the similarities:\n",
        "\n",
        "\\[\n",
        "\\mathbf{h}_i = \\frac{\\mathbf{h}_i}{\\|\\mathbf{h}_i\\|_2}\n",
        "\\]\n",
        "\\[\n",
        "\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_j) = \\frac{\\mathbf{h}_i \\cdot \\mathbf{h}_j}{\\tau}\n",
        "\\]\n",
        "\n",
        "### Comparison\n",
        "\n",
        "#### Objective\n",
        "\n",
        "- **SimCSE**: Focuses on maximizing similarity between positive pairs and minimizing similarity between negative pairs.\n",
        "- **Enhanced Combined**: In addition to maximizing/minimizing similarities, it directly optimizes the rank order of pairs.\n",
        "\n",
        "#### Equation Comparison\n",
        "\n",
        "- **SimCSE**:\n",
        "  \\[\n",
        "  \\mathcal{L}_{\\text{SimCSE}} = - \\log \\frac{\\exp(\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+))}{\\sum_{j=1}^{N} \\exp(\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_j))}\n",
        "  \\]\n",
        "\n",
        "- **Enhanced Combined**:\n",
        "  \\[\n",
        "  \\mathcal{L}_{\\text{combined}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot (1 - \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+))^2 + (1 - y_i) \\cdot \\max(0, \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{margin})^2 \\right] + \\frac{1}{N} \\sum_{i,j} \\left[ \\max(0, 1 - (\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{sim}(\\mathbf{h}_j, \\mathbf{h}_j^-))) \\cdot \\mathbb{I}(y_i > y_j) \\right]\n",
        "  \\]\n",
        "\n",
        "#### Optimized Metric\n",
        "\n",
        "- **SimCSE**: Focuses on contrastive separation, indirectly improving metrics like cosine similarity.\n",
        "- **Enhanced Combined**: Directly optimizes rank order through pairwise ranking loss, targeting improvements in rank correlation metrics such as Spearman’s rank correlation coefficient.\n",
        "\n",
        "#### Normalization and Scaling\n",
        "\n",
        "- **SimCSE**: Uses normalization to ensure meaningful cosine similarities.\n",
        "- **Enhanced Combined**: Uses normalization and scaling factor \\(\\tau\\) to sharpen similarity scores, aiding in differentiation.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The enhanced combined loss function addresses a specific limitation in SimCSE by directly optimizing the rank order of similarity scores through the pairwise ranking loss. This makes it more suitable for tasks like STS (Semantic Textual Similarity), where the goal is to achieve high rank correlation, particularly improving metrics like the Spearman’s rank correlation coefficient. The combined approach ensures both good separability of embeddings and correct rank order, providing a more robust learning signal compared to using contrastive loss alone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMteavuTphV2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYwKOcWfpXq3"
      },
      "source": [
        "### Difference Between Pairwise Ranking Loss and Contrastive Loss\n",
        "\n",
        "#### Contrastive Loss\n",
        "\n",
        "Contrastive loss is a distance-based loss function used to learn embeddings such that similar instances are close to each other in the embedding space while dissimilar instances are far apart. It is typically used in tasks where the model needs to distinguish between similar and dissimilar pairs.\n",
        "\n",
        "**Mathematical Formulation:**\n",
        "\n",
        "For a given pair of embeddings \\((\\mathbf{h}_i, \\mathbf{h}_i^+)\\) (anchor and positive) and a margin \\(\\text{margin}\\):\n",
        "\n",
        "\\[\n",
        "\\mathcal{L}_{\\text{contrastive}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot (1 - \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+))^2 + (1 - y_i) \\cdot \\max(0, \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{margin})^2 \\right]\n",
        "\\]\n",
        "\n",
        "- \\(y_i\\): Binary label indicating whether \\(\\mathbf{h}_i\\) and \\(\\mathbf{h}_i^+\\) are similar (1) or dissimilar (0).\n",
        "- \\(\\text{sim}(\\mathbf{u}, \\mathbf{v})\\): Cosine similarity between embeddings \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\).\n",
        "- The loss encourages similar pairs to have high similarity (close to 1) and dissimilar pairs to have similarity less than the margin.\n",
        "\n",
        "#### Pairwise Ranking Loss\n",
        "\n",
        "Pairwise ranking loss is designed to optimize the ranking order of pairs, which is particularly useful for tasks like information retrieval or ranking, where the relative order of predictions is more important than their absolute values. This loss function penalizes incorrect rank orders directly.\n",
        "\n",
        "**Mathematical Formulation:**\n",
        "\n",
        "For pairs of similarity scores \\((\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+), \\text{sim}(\\mathbf{h}_j, \\mathbf{h}_j^-))\\) and the ground truth ordering \\(y_i > y_j\\):\n",
        "\n",
        "\\[\n",
        "\\mathcal{L}_{\\text{ranking}} = \\frac{1}{N} \\sum_{i,j} \\left[ \\max(0, 1 - (\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{sim}(\\mathbf{h}_j, \\mathbf{h}_j^-))) \\cdot \\mathbb{I}(y_i > y_j) \\right]\n",
        "\\]\n",
        "\n",
        "- \\(\\mathbb{I}(y_i > y_j)\\): Indicator function that is 1 if the rank order \\(y_i > y_j\\) is correct, and 0 otherwise.\n",
        "- The loss penalizes incorrect rank orders, ensuring that the difference between correct and incorrect orders is at least 1.\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "1. **Objective**:\n",
        "   - **Contrastive Loss**: Focuses on minimizing the distance between similar pairs and maximizing the distance between dissimilar pairs based on a margin.\n",
        "   - **Pairwise Ranking Loss**: Focuses on the relative ordering of pairs, directly optimizing the rank order based on similarity scores.\n",
        "\n",
        "2. **Penalty Mechanism**:\n",
        "   - **Contrastive Loss**: Penalizes pairs based on their similarity scores and a predefined margin.\n",
        "   - **Pairwise Ranking Loss**: Penalizes the relative ranking of similarity scores, ensuring correct ordering by imposing a margin between correct and incorrect pairs.\n",
        "\n",
        "3. **Application**:\n",
        "   - **Contrastive Loss**: Often used in metric learning tasks where the goal is to learn a distance metric or embedding space (e.g., face verification).\n",
        "   - **Pairwise Ranking Loss**: Commonly used in ranking tasks, such as information retrieval, where the order of items is crucial (e.g., search engine results).\n",
        "\n",
        "4. **Impact on Embedding Space**:\n",
        "   - **Contrastive Loss**: Ensures that similar items are clustered together and dissimilar items are pushed apart.\n",
        "   - **Pairwise Ranking Loss**: Ensures that the order of similarity scores aligns with the ground truth ranking, potentially resulting in a more nuanced embedding space that respects relative similarities.\n",
        "\n",
        "### Enhanced Combined Loss\n",
        "\n",
        "Combining both losses leverages the strengths of each:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def enhanced_combined_loss(y_true: torch.Tensor, y_pred: torch.Tensor, margin: float = 1.0, tau: float = 20.0) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute enhanced combined contrastive, cross-entropy, and pairwise ranking loss\n",
        "\n",
        "    :param y_true: torch.Tensor, ground truth.\n",
        "        The y_true must be zigzag style, such as [x[0][0], x[0][1], x[1][0], x[1][1], ...], where (x[0][0], x[0][1]) stands for a pair.\n",
        "    :param y_pred: torch.Tensor, model output.\n",
        "        The y_pred must be zigzag style, such as [o[0][0], o[0][1], o[1][0], o[1][1], ...], where (o[0][0], o[0][1]) stands for a pair.\n",
        "    :param margin: float, margin factor, default 1.0\n",
        "    :param tau: float, scale factor, default 20\n",
        "\n",
        "    :return: torch.Tensor, loss value\n",
        "    \"\"\"  # NOQA\n",
        "    \n",
        "    # Ensure y_true is in the correct format\n",
        "    y_true_pairs = y_true[::2, 0]\n",
        "    y_true_pairs = (y_true_pairs[:, None] < y_true_pairs[None, :]).float()\n",
        "    \n",
        "    # Normalize predictions to compute cosine similarity\n",
        "    y_pred = F.normalize(y_pred, p=2, dim=1)\n",
        "    \n",
        "    # Compute cosine similarity for pairs and scale by tau\n",
        "    cosine_sim = torch.sum(y_pred[::2] * y_pred[1::2], dim=1) * tau\n",
        "    \n",
        "    # Contrastive Loss\n",
        "    pos_pairs = y_true_pairs * torch.pow(1 - cosine_sim, 2)\n",
        "    neg_pairs = (1 - y_true_pairs) * torch.pow(torch.clamp(cosine_sim - margin, min=0.0), 2)\n",
        "    contrastive_loss = torch.mean(pos_pairs + neg_pairs)\n",
        "    \n",
        "    # Pairwise Ranking Loss\n",
        "    # Compute differences in similarity scores for pairwise ranking\n",
        "    y_pred_diff = cosine_sim[:, None] - cosine_sim[None, :]\n",
        "    y_true_diff = y_true_pairs[:, None] - y_true_pairs[None, :]\n",
        "    \n",
        "    # Create a mask to consider only positive differences\n",
        "    mask = (y_true_diff > 0).float()\n",
        "    \n",
        "    # Compute pairwise ranking loss\n",
        "    pairwise_ranking_loss = torch.mean(mask * F.relu(1 - y_pred_diff))\n",
        "    \n",
        "    # Combined Loss\n",
        "    combined_loss_value = contrastive_loss + pairwise_ranking_loss\n",
        "    \n",
        "    return combined_loss_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXUHFKiUpYJr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl5SHWArrA-h"
      },
      "source": [
        "### Difference Between Pairwise Ranking Loss and Contrastive Loss\n",
        "\n",
        "#### Contrastive Loss\n",
        "\n",
        "Contrastive loss is a distance-based loss function used to learn embeddings such that similar instances are close to each other in the embedding space while dissimilar instances are far apart. It is typically used in tasks where the model needs to distinguish between similar and dissimilar pairs.\n",
        "\n",
        "**Mathematical Formulation:**\n",
        "\n",
        "For a given pair of embeddings $(\\mathbf{h}_i, \\mathbf{h}_i^+)$ (anchor and positive) and a margin $\\text{margin}$:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{contrastive}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot (1 - \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+))^2 + (1 - y_i) \\cdot \\max(0, \\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{margin})^2 \\right]\n",
        "$$\n",
        "\n",
        "- $y_i$: Binary label indicating whether $\\mathbf{h}_i$ and $\\mathbf{h}_i^+$ are similar (1) or dissimilar (0).\n",
        "- $\\text{sim}(\\mathbf{u}, \\mathbf{v})$: Cosine similarity between embeddings $\\mathbf{u}$ and $\\mathbf{v}$.\n",
        "- The loss encourages similar pairs to have high similarity (close to 1) and dissimilar pairs to have similarity less than the margin.\n",
        "\n",
        "#### Pairwise Ranking Loss\n",
        "\n",
        "Pairwise ranking loss is designed to optimize the ranking order of pairs, which is particularly useful for tasks like information retrieval or ranking, where the relative order of predictions is more important than their absolute values. This loss function penalizes incorrect rank orders directly.\n",
        "\n",
        "**Mathematical Formulation:**\n",
        "\n",
        "For pairs of similarity scores $(\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+), \\text{sim}(\\mathbf{h}_j, \\mathbf{h}_j^-))$ and the ground truth ordering $y_i > y_j$:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{ranking}} = \\frac{1}{N} \\sum_{i,j} \\left[ \\max(0, 1 - (\\text{sim}(\\mathbf{h}_i, \\mathbf{h}_i^+) - \\text{sim}(\\mathbf{h}_j, \\mathbf{h}_j^-))) \\cdot \\mathbb{I}(y_i > y_j) \\right]\n",
        "$$\n",
        "\n",
        "- $\\mathbb{I}(y_i > y_j)$: Indicator function that is 1 if the rank order $y_i > y_j$ is correct, and 0 otherwise.\n",
        "- The loss penalizes incorrect rank orders, ensuring that the difference between correct and incorrect orders is at least 1.\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "1. **Objective**:\n",
        "   - **Contrastive Loss**: Focuses on minimizing the distance between similar pairs and maximizing the distance between dissimilar pairs based on a margin.\n",
        "   - **Pairwise Ranking Loss**: Focuses on the relative ordering of pairs, directly optimizing the rank order based on similarity scores.\n",
        "\n",
        "2. **Penalty Mechanism**:\n",
        "   - **Contrastive Loss**: Penalizes pairs based on their similarity scores and a predefined margin.\n",
        "   - **Pairwise Ranking Loss**: Penalizes the relative ranking of similarity scores, ensuring correct ordering by imposing a margin between correct and incorrect pairs.\n",
        "\n",
        "3. **Application**:\n",
        "   - **Contrastive Loss**: Often used in metric learning tasks where the goal is to learn a distance metric or embedding space (e.g., face verification).\n",
        "   - **Pairwise Ranking Loss**: Commonly used in ranking tasks, such as information retrieval, where the order of items is crucial (e.g., search engine results).\n",
        "\n",
        "4. **Impact on Embedding Space**:\n",
        "   - **Contrastive Loss**: Ensures that similar items are clustered together and dissimilar items are pushed apart.\n",
        "   - **Pairwise Ranking Loss**: Ensures that the order of similarity scores aligns with the ground truth ranking, potentially resulting in a more nuanced embedding space that respects relative similarities.\n",
        "\n",
        "### Enhanced Combined Loss\n",
        "\n",
        "Combining both losses leverages the strengths of each:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def enhanced_combined_loss(y_true: torch.Tensor, y_pred: torch.Tensor, margin: float = 1.0, tau: float = 20.0) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute enhanced combined contrastive, cross-entropy, and pairwise ranking loss\n",
        "\n",
        "    :param y_true: torch.Tensor, ground truth.\n",
        "        The y_true must be zigzag style, such as [x[0][0], x[0][1], x[1][0], x[1][1], ...], where (x[0][0], x[0][1]) stands for a pair.\n",
        "    :param y_pred: torch.Tensor, model output.\n",
        "        The y_pred must be zigzag style, such as [o[0][0], o[0][1], o[1][0], o[1][1], ...], where (o[0][0], o[0][1]) stands for a pair.\n",
        "    :param margin: float, margin factor, default 1.0\n",
        "    :param tau: float, scale factor, default 20\n",
        "\n",
        "    :return: torch.Tensor, loss value\n",
        "    \"\"\"  # NOQA\n",
        "    \n",
        "    # Ensure y_true is in the correct format\n",
        "    y_true_pairs = y_true[::2, 0]\n",
        "    y_true_pairs = (y_true_pairs[:, None] < y_true_pairs[None, :]).float()\n",
        "    \n",
        "    # Normalize predictions to compute cosine similarity\n",
        "    y_pred = F.normalize(y_pred, p=2, dim=1)\n",
        "    \n",
        "    # Compute cosine similarity for pairs and scale by tau\n",
        "    cosine_sim = torch.sum(y_pred[::2] * y_pred[1::2], dim=1) * tau\n",
        "    \n",
        "    # Contrastive Loss\n",
        "    pos_pairs = y_true_pairs * torch.pow(1 - cosine_sim, 2)\n",
        "    neg_pairs = (1 - y_true_pairs) * torch.pow(torch.clamp(cosine_sim - margin, min=0.0), 2)\n",
        "    contrastive_loss = torch.mean(pos_pairs + neg_pairs)\n",
        "    \n",
        "    # Pairwise Ranking Loss\n",
        "    # Compute differences in similarity scores for pairwise ranking\n",
        "    y_pred_diff = cosine_sim[:, None] - cosine_sim[None, :]\n",
        "    y_true_diff = y_true_pairs[:, None] - y_true_pairs[None, :]\n",
        "    \n",
        "    # Create a mask to consider only positive differences\n",
        "    mask = (y_true_diff > 0).float()\n",
        "    \n",
        "    # Compute pairwise ranking loss\n",
        "    pairwise_ranking_loss = torch.mean(mask * F.relu(1 - y_pred_diff))\n",
        "    \n",
        "    # Combined Loss\n",
        "    combined_loss_value = contrastive_loss + pairwise_ranking_loss\n",
        "    \n",
        "    return combined_loss_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH8Ws3R3rBsr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FWJYPqj-JTYq",
        "oKd63ogoJZYp",
        "bXi45wR2KFFv",
        "yVDqc2HoKXpU",
        "yDR2QBJiKnBf",
        "kDsjQhxkKq1Y",
        "OpiS9-RxKuun",
        "6m5rbe2hLZeo",
        "IntQVlnn4h65"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10d6d3d1a3ce4af4a4c5bbd28b5c317b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b89294729fbe4faa8e5788b6708a1ef5",
            "max": 1428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1796c7cf621f4961b6bcb5c1c6a24402",
            "tabbable": null,
            "tooltip": null,
            "value": 1428
          }
        },
        "1796c7cf621f4961b6bcb5c1c6a24402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f651f94396842a083f96319f8f1064b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2dd9ae066c1d4e2684784dbb95905c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4643a49f0b30415db80c1151cd29a7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "723a89a69f5e4ad58bddb313a9dcf082": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d84521851c7d48b69ba88461bd337458",
              "IPY_MODEL_10d6d3d1a3ce4af4a4c5bbd28b5c317b",
              "IPY_MODEL_f8e64c7d5e8547afbb986c0ca4bb6f14"
            ],
            "layout": "IPY_MODEL_fc1a3dcd0ed94737a4de4d8468a2afe5",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b89294729fbe4faa8e5788b6708a1ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d12622318a45be85a218115a62bb46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84521851c7d48b69ba88461bd337458": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b9d12622318a45be85a218115a62bb46",
            "placeholder": "​",
            "style": "IPY_MODEL_4643a49f0b30415db80c1151cd29a7ce",
            "tabbable": null,
            "tooltip": null,
            "value": "Map (num_proc=8): 100%"
          }
        },
        "f8e64c7d5e8547afbb986c0ca4bb6f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2dd9ae066c1d4e2684784dbb95905c62",
            "placeholder": "​",
            "style": "IPY_MODEL_1f651f94396842a083f96319f8f1064b",
            "tabbable": null,
            "tooltip": null,
            "value": " 1428/1428 [00:01&lt;00:00, 1701.14 examples/s]"
          }
        },
        "fc1a3dcd0ed94737a4de4d8468a2afe5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
